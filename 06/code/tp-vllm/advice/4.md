整体方向明显对了：你已经把三个“最致命”的坑都补上了——

* causal mask 改成 bool + masked_fill，避免 0 * -inf → NaN（非常关键）。
* KV cache 返回的是未 repeat 的 (k_kv, v_kv)，不会在 GQA 下把 cache 放大（关键）。 
* QKVParallelLinear 改成“全局 output_size → ColumnParallelLinear 内部分片”，并且 weight_loader_qkv 改为沿 dim=0（out_features）切分（方向正确）。 

但现在还存在几处“仍可能导致结果不对 / 不稳定 / 难以对齐 HF”的问题。我按优先级给出最合理的下一步修正。

1. RoPE 的 shape/调用方式大概率仍然不对（高优先级）
   你在 TensorParallelAttention 里：

* 先把 q,k 转成 [batch, heads, seq, dim] 形状。
* 然后为了 rotary_emb 做了 q_for_rope/k_for_rope = transpose 回 [batch, seq, heads, dim]，并用 rotary_emb(k_for_rope, position_ids) 得到 cos/sin。
* 但你随后调用 apply_rotary_pos_emb(q, k, cos, sin) 的时候，传入的 q,k 还是 [batch, heads, seq, dim]，而 cos/sin 的 shape 很可能是基于 [batch, seq, …] 生成的。

在 HF 的 Qwen2/Qwen2.5 实现里，rotary_emb 和 apply_rotary_pos_emb 的期望 shape 组合比较严格；你现在这种“先用 k_for_rope 取 cos/sin，再对 q,k 应用”的思路没问题，但必须保证 cos/sin 的维度与 apply_rotary_pos_emb 的实现完全匹配，否则会 silently broadcast 到错误维度，导致位置编码错而模型输出坍缩或异常。

最合理的解决方案
不要在你自己的模块里“猜”HF 的 RoPE 张量布局。直接对齐 HF 的调用路径：用 HF layer 的 attention forward 里同样的 shape 流转，复制它的几行 RoPE 处理到你的 TP attention（仅替换 qkv_proj/o_proj 为 TP 版本）。这比继续 try/except 更可靠。

你现在用了 try/except 并在失败时继续跑，这会让“RoPE 实际没生效”但程序仍继续，结果必错且很难定位。
建议：RoPE 失败时直接 raise（至少在 debug 模式），不要吞异常。

2. 你目前的 generate 仍然没有真正使用 KV cache（中优先级，但会严重影响行为/性能）
   HybridTPModel.forward 的签名支持 kv_caches，但 generate 里每一步 decode 都在做 logits = self.forward(generated_ids)，没有把 kv_caches 传进去，也没有在下一步复用。

这会导致两个问题：

* 语义上：每一步都是“重新 prefill 全序列”，position_ids 每次都是从 0..len-1 重建（这本身可以正确，但很慢）。
* 工程上：你测试时更难定位“cache 路径”的 bug，因为根本没走 cache 路径。

最合理的方案
把 generate 改成两段：

* prefill：forward(input_ids, kv_caches=None) → 同时返回 kv_caches（你需要让 forward 返回 kv_caches 或提供一个 forward_with_cache）
* decode：每步只喂 new_token 的 input_ids[:, -1:]，position_ids = 当前绝对位置，并传入 kv_caches 做增量更新

否则你做 TP+PA 的意义会被彻底稀释。

3. QKVParallelLinear 的 “KV replication” 逻辑不完整（中优先级）
   你在 QKVParallelLinear 里实现了“如果 tp_size >= num_kv_heads 则 KV 复制”的分支：num_kv_heads_local=1，num_kv_head_replicas=tp_size/num_kv_heads。

但 _shard_weight 对 Q 的切分是标准的 start_idx = tp_rank * shard_size；对 KV 的复制用 kv_head_idx = tp_rank // num_kv_head_replicas。

这里的关键是：当 KV 被复制时，“每个 rank 的 K/V shard”在逻辑上应该对应某个 kv head group；但你的 split_qkv / attention 中的 repeat_interleave 逻辑是基于 local 的 num_kv_heads_local 与 num_heads_local 计算 repeat_factor。

如果 Qwen2.5 的配置不是这种极端 KV 复制场景，这条暂时不会触发；但作为“更接近真实 vLLM”，你应该：

* 明确区分：KV head 的 partition vs replication 两种模式下，attention 里 heads 的对齐规则
* 增加断言：num_heads_local % num_kv_heads_local == 0（你现在隐含假设了这一点）

4. HybridTPModel 里 LM head 没有 TP 处理，容易让你误判“TP correctness”
   你现在为了简化，把 lm_head 保留为 HF 原版，每个 rank 都有全 vocab 的 lm_head。

这在 demo 是可以的，但会有一个副作用：即便 TP attention/MLP 有细微差异，lm_head 的全量计算会掩盖一些并行路径错误（尤其是你还没有做跨 rank 的 logits 一致性检查）。

最合理的补强
在 rank0 上做一个 sanity check：

* 在 forward 的关键点（例如每层输出、最终 logits），对 rank0 和 rank1 做 all_reduce/比较（或 gather 后比较 max abs diff）
* 至少确保 TP 后的 hidden_states 在各 rank 是一致的（RowParallel 的 all_reduce 本应保证这一点）

5. weight_loader 仍然是“每个 rank 都 load 全量 state_dict”（不是错误，但不够 vLLM）
   你在 weight_loader.py 明确写了 load_on_all_ranks=True 默认全量加载。
   这不影响正确性，但不符合你“每 rank 只存 shard”那句承诺。要更像 vLLM，需要：

* rank0 load full
* broadcast 每层每个权重的 shard 到对应 rank
  否则内存统计和真实 vLLM 会偏离。

最合理的下一步（建议你按顺序做）

1. RoPE：移除 try/except 吞异常；严格对齐 HF 的 Qwen2.5 RoPE 调用路径（这是目前最可能仍然导致“结果不对”的点）。
2. generate：实现真正的 kv_caches 增量 decode（否则你无法验证你 attention 的 cache 路径）。
3. 加一个“对齐测试”：同一 batch 输入，HF 原模型 vs 你的 HybridTPModel（tp=1）在 logits 上做 top-1 一致性或 max error 检查；然后 tp=2 做跨 rank 一致性检查。

如果你把你最新一次运行的现象（现在是否还输出 inglesingles 或者变成别的坍缩）贴出来，我可以更精确地判断：是 RoPE 没真正生效，还是 QKV 的权重键/形状仍有偏差（比如 Qwen2.5 是否 actually 用 fused qkv 权重名，还是 separate q_proj/k_proj/v_proj）。
