#!/bin/bash
# Script to manage k3d cluster with multiple vLLM models (single engine: vLLM only)
# Uses namespace 'multi-models' to isolate from multi-engines deployment
# 
# Usage:
#   ./manage-cluster-multi-models.sh [stop|start|restart|status]
#   NAMESPACE=custom-ns ./manage-cluster-multi-models.sh start  # Use custom namespace
#
# Examples:
#   ./manage-cluster-multi-models.sh stop      # Stop the cluster
#   ./manage-cluster-multi-models.sh start      # Start the cluster (deploys multiple vLLM models in 'multi-models' namespace)
#   ./manage-cluster-multi-models.sh restart   # Restart the cluster
#   ./manage-cluster-multi-models.sh status    # Show cluster status

set -e

CLUSTER_NAME="mycluster-gpu"
NAMESPACE="${NAMESPACE:-multi-models}"  # Namespace for multi-model deployment (vLLM only, multiple models)

# Function to show usage
show_usage() {
    echo "Usage: $0 [stop|start|restart|status]"
    echo ""
    echo "Commands:"
    echo "  stop     - Stop the k3d cluster"
    echo "  start    - Start the k3d cluster and deploy multiple vLLM models"
    echo "  restart  - Restart the k3d cluster"
    echo "  status   - Show cluster status"
    exit 1
}

# Function to stop cluster
stop_cluster() {
    echo "=========================================="
    echo "Stopping k3d Cluster: $CLUSTER_NAME"
    echo "=========================================="
    echo ""
    
    if ! k3d cluster list | grep -q "$CLUSTER_NAME"; then
        echo "‚ö†Ô∏è  Cluster $CLUSTER_NAME not found"
        exit 1
    fi
    
    # Stop port-forward processes before stopping cluster
    # This prevents orphaned processes when cluster stops
    echo "Checking for active port-forward processes..."
    PF_PIDS=$(pgrep -f "kubectl port-forward" 2>/dev/null || true)
    if [ -n "$PF_PIDS" ]; then
        echo "  Found port-forward processes, stopping them..."
        for pid in $PF_PIDS; do
            # Get the command line to show what we're stopping
            PF_CMD=$(ps -p $pid -o args= 2>/dev/null | head -1 || echo "unknown")
            echo "    Stopping port-forward (PID: $pid): $PF_CMD"
            kill $pid 2>/dev/null || true
        done
        sleep 1
        # Force kill if still running
        for pid in $PF_PIDS; do
            if ps -p $pid > /dev/null 2>&1; then
                echo "    Force killing port-forward (PID: $pid)..."
                kill -9 $pid 2>/dev/null || true
            fi
        done
        echo "  ‚úÖ Port-forward processes stopped"
    else
        echo "  No port-forward processes found"
    fi
    echo ""
    
    echo "Stopping cluster..."
    k3d cluster stop "$CLUSTER_NAME"
    
    # Also stop manually created agent nodes (created via docker run)
    echo ""
    echo "Stopping manually created agent nodes..."
    MANUAL_AGENTS=$(docker ps -a --filter "label=k3d.cluster=$CLUSTER_NAME" --filter "label=k3d.role=agent" --format "{{.Names}}" | grep -v "^k3d-$CLUSTER_NAME" || true)
    if [ -n "$MANUAL_AGENTS" ]; then
        for agent in $MANUAL_AGENTS; do
            if docker ps --format "{{.Names}}" | grep -q "^${agent}$"; then
                echo "  Stopping $agent..."
                docker stop "$agent" 2>/dev/null || true
            fi
        done
    fi
    
    echo ""
    echo "‚úÖ Cluster stopped"
    echo ""
    echo "üìä Cluster status:"
    k3d cluster list
    echo ""
    echo "üìä Docker containers status:"
    docker ps -a --filter "name=k3d-$CLUSTER_NAME" --filter "label=k3d.cluster=$CLUSTER_NAME" --format "table {{.Names}}\t{{.Status}}"
}

# Function to start cluster
start_cluster() {
    echo "=========================================="
    echo "Starting k3d Cluster: $CLUSTER_NAME"
    echo "=========================================="
    echo ""
    
    if ! k3d cluster list | grep -q "$CLUSTER_NAME"; then
        echo "‚ùå Error: Cluster $CLUSTER_NAME not found"
        echo "   Please create the cluster first (see README)"
        exit 1
    fi
    
    echo "Starting cluster..."
    k3d cluster start "$CLUSTER_NAME"
    
    # Also start manually created agent nodes if they exist
    echo ""
    echo "Starting manually created agent nodes..."
    MANUAL_AGENTS=$(docker ps -a --filter "label=k3d.cluster=$CLUSTER_NAME" --filter "label=k3d.role=agent" --format "{{.Names}}" | grep -v "^k3d-$CLUSTER_NAME" || true)
    if [ -n "$MANUAL_AGENTS" ]; then
        for agent in $MANUAL_AGENTS; do
            if ! docker ps --format "{{.Names}}" | grep -q "^${agent}$"; then
                echo "  Starting $agent..."
                docker start "$agent" 2>/dev/null || true
            fi
        done
    fi
    
    echo ""
    echo "‚è≥ Waiting for cluster to be ready..."
    sleep 5
    
    # Wait for NVIDIA device plugin to be ready (important for GPU workloads)
    echo ""
    echo "‚è≥ Waiting for NVIDIA device plugin to register GPUs..."
    echo "   (This may take 20-30 seconds after cluster start)"
    for i in {1..30}; do
        if kubectl get nodes -o json | python3 -c "import sys, json; d=json.load(sys.stdin); nodes=[n for n in d['items'] if n['status'].get('allocatable', {}).get('nvidia.com/gpu')]; exit(0 if nodes else 1)" 2>/dev/null; then
            echo "   ‚úÖ GPUs detected on nodes"
            break
        fi
        if [ $i -eq 30 ]; then
            echo "   ‚ö†Ô∏è  GPUs not yet detected (device plugin may need more time)"
        else
            echo -n "."
            sleep 1
        fi
    done
    echo ""
    
    # Merge kubeconfig
    echo "üîó Merging kubeconfig..."
    k3d kubeconfig merge "$CLUSTER_NAME" --kubeconfig-merge-default
    
    # Fix kubeconfig server address if needed
    export KUBECONFIG=$HOME/.kube/config
    KUBE_SERVER=$(kubectl config view -o jsonpath='{.clusters[?(@.name=="k3d-'$CLUSTER_NAME'")].cluster.server}' 2>/dev/null || echo "")
    if [[ "$KUBE_SERVER" == *"0.0.0.0"* ]]; then
        echo "üîß Fixing kubeconfig server address..."
        kubectl config set-cluster "k3d-$CLUSTER_NAME" --server=$(echo $KUBE_SERVER | sed 's/0.0.0.0/127.0.0.1/')
    fi
    
    # Create namespace for multi-model deployment
    echo ""
    echo "üì¶ Creating namespace: $NAMESPACE"
    kubectl create namespace "$NAMESPACE" 2>/dev/null || echo "  ‚úÖ Namespace already exists"
    
    # Create HF_TOKEN secret in namespace if it doesn't exist
    if [ -n "$HF_TOKEN" ]; then
        echo "  üîê Creating/updating HF_TOKEN secret in namespace..."
        kubectl create secret generic hf-token-secret \
          --from-literal=token="$HF_TOKEN" \
          --namespace "$NAMESPACE" \
          --dry-run=client -o yaml | kubectl apply -f - 2>/dev/null || echo "    ‚ö†Ô∏è  Failed to create secret"
    else
        echo "  ‚ö†Ô∏è  HF_TOKEN not set, secret may need to be created manually"
    fi
    
    # Auto-deploy multiple vLLM models (single engine: vLLM only)
    # This script deploys multiple models using the same inference engine (vLLM)
    echo ""
    echo "üöÄ Checking and deploying vLLM models (multi-model, single engine) in namespace: $NAMESPACE..."
    SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
    
    # List of vLLM models to deploy
    # Format: "yaml_file_path:resource_name:resource_type"
    # resource_type: "deployment" for Deployment resources (both models use Deployment for consistency)
    VLLM_MODELS=(
        "vllm/llama-3.2-1b.yaml:vllm-llama-32-1b-pod:deployment"      # Deployment resource
        "vllm/phi-tiny-moe.yaml:vllm-phi-tiny-moe-pod:deployment"      # Deployment resource
    )
    
    for model_config in "${VLLM_MODELS[@]}"; do
        IFS=':' read -r yaml_file resource_name resource_type <<< "$model_config"
        yaml_path="$SCRIPT_DIR/$yaml_file"
        
        if [ ! -f "$yaml_path" ]; then
            echo "  ‚ö†Ô∏è  Skipping $resource_name (YAML not found: $yaml_path)"
            continue
        fi
        
        # Check if resource exists based on type
        if [ "$resource_type" = "pod" ]; then
            if ! kubectl get pod "$resource_name" -n "$NAMESPACE" &>/dev/null; then
                echo "  üì¶ Deploying $resource_name (Pod)..."
                kubectl apply -f "$yaml_path" -n "$NAMESPACE" 2>/dev/null || echo "    ‚ö†Ô∏è  Failed to deploy $resource_name (may need HF_TOKEN secret or model files)"
            else
                echo "  ‚úÖ $resource_name (Pod) already exists"
            fi
        elif [ "$resource_type" = "deployment" ]; then
            if ! kubectl get deployment "$resource_name" -n "$NAMESPACE" &>/dev/null; then
                echo "  üì¶ Deploying $resource_name (Deployment)..."
                kubectl apply -f "$yaml_path" -n "$NAMESPACE" 2>/dev/null || echo "    ‚ö†Ô∏è  Failed to deploy $resource_name (may need model files)"
            else
                echo "  ‚úÖ $resource_name (Deployment) already exists"
            fi
        fi
    done
    
    echo ""
    echo "‚úÖ Cluster started"
    echo ""
    echo "üìä Cluster status:"
    k3d cluster list
    echo ""
    echo "üìä Node status:"
    kubectl get nodes
    echo ""
    echo "üìä Pod status in namespace $NAMESPACE:"
    kubectl get pods -n "$NAMESPACE"
    echo ""
    echo "üìä Services in namespace $NAMESPACE:"
    kubectl get svc -n "$NAMESPACE"
    
    # Deploy API Gateway and Ingress (optional, in default namespace)
    echo ""
    echo "üåê Checking API Gateway and Ingress..."
    SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
    
    # Deploy API Gateway if it doesn't exist
    if ! kubectl get pod vllm-api-gateway -n default &>/dev/null; then
        echo "  üì¶ Deploying API Gateway..."
        if [ -f "$SCRIPT_DIR/gateway/deploy-gateway.sh" ]; then
            cd "$SCRIPT_DIR/gateway" && ./deploy-gateway.sh 2>/dev/null || echo "    ‚ö†Ô∏è  Failed to deploy Gateway"
            cd - > /dev/null
        else
            echo "    ‚ö†Ô∏è  Gateway deployment script not found"
        fi
    else
        echo "  ‚úÖ API Gateway already exists"
    fi
    
    # Deploy Traefik Ingress if it doesn't exist (optional, for production access)
    if ! kubectl get ingress vllm-api-gateway-ingress -n default &>/dev/null; then
        echo "  üì¶ Deploying Traefik Ingress (optional, for HTTPS access)..."
        # Create TLS secret if it doesn't exist
        if ! kubectl get secret vllm-api-tls -n default &>/dev/null; then
            echo "    üîê Creating TLS certificate..."
            openssl req -x509 -nodes -days 365 -newkey rsa:2048 \
              -keyout /tmp/tls.key \
              -out /tmp/tls.crt \
              -subj "/CN=localhost" \
              -addext "subjectAltName=DNS:localhost,DNS:*.localhost,IP:127.0.0.1,IP:::1" 2>/dev/null || echo "      ‚ö†Ô∏è  OpenSSL not available, skipping TLS secret"
            
            if [ -f /tmp/tls.crt ] && [ -f /tmp/tls.key ]; then
                kubectl create secret tls vllm-api-tls \
                  --cert=/tmp/tls.crt \
                  --key=/tmp/tls.key \
                  -n default 2>/dev/null || echo "      ‚ö†Ô∏è  Failed to create TLS secret"
                rm -f /tmp/tls.crt /tmp/tls.key
            fi
        fi
        
        # Apply Ingress configuration
        if [ -f "$SCRIPT_DIR/gateway/ingress-tls-traefik.yaml" ]; then
            kubectl apply -f "$SCRIPT_DIR/gateway/ingress-tls-traefik.yaml" 2>/dev/null || echo "    ‚ö†Ô∏è  Failed to deploy Ingress"
            echo "    ‚úÖ Ingress deployed (access via https://localhost)"
        else
            echo "    ‚ö†Ô∏è  Ingress YAML not found: $SCRIPT_DIR/gateway/ingress-tls-traefik.yaml"
        fi
    else
        echo "  ‚úÖ Traefik Ingress already exists"
    fi
}

# Function to restart cluster
restart_cluster() {
    echo "=========================================="
    echo "Restarting k3d Cluster: $CLUSTER_NAME"
    echo "=========================================="
    echo ""
    stop_cluster
    echo ""
    sleep 2
    start_cluster
}

# Function to show status
show_status() {
    echo "=========================================="
    echo "k3d Cluster Status: $CLUSTER_NAME"
    echo "=========================================="
    echo ""
    
    echo "üìä Cluster list:"
    k3d cluster list
    echo ""
    
    # Check if cluster is running by checking if servers/agents are running (not 0/1)
    CLUSTER_STATUS=$(k3d cluster list --no-headers | grep "^$CLUSTER_NAME" | awk '{print $2, $3}' || echo "")
    if echo "$CLUSTER_STATUS" | grep -qE "[1-9]/[0-9]+.*[1-9]/[0-9]+"; then
        # Switch to cluster context
        kubectl config use-context "k3d-$CLUSTER_NAME" 2>/dev/null || true
        
        echo "üìä Kubernetes nodes:"
        kubectl get nodes 2>/dev/null || echo "  Unable to connect to cluster"
        echo ""
        
        echo "üìä Namespaces:"
        kubectl get namespaces 2>/dev/null | grep -E "multi-engines|multi-models|NAME" || echo "  Unable to list namespaces"
        echo ""
        
        echo "üìä Pods in namespace $NAMESPACE:"
        kubectl get pods -n "$NAMESPACE" 2>/dev/null || echo "  Unable to list pods in namespace $NAMESPACE"
        echo ""
        
        echo "üìä Services in namespace $NAMESPACE:"
        kubectl get svc -n "$NAMESPACE" 2>/dev/null | head -10 || echo "  Unable to list services in namespace $NAMESPACE"
    else
        echo "‚ö†Ô∏è  Cluster is not running (servers/agents: $CLUSTER_STATUS)"
    fi
}

# Main script logic
case "${1:-}" in
    stop)
        stop_cluster
        ;;
    start)
        start_cluster
        ;;
    restart)
        restart_cluster
        ;;
    status)
        show_status
        ;;
    *)
        show_usage
        ;;
esac
