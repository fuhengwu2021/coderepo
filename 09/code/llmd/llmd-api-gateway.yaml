apiVersion: v1
kind: ConfigMap
metadata:
  name: llmd-api-gateway-code
  namespace: llm-d-multi-model
data:
  api-gateway.py: |
    """
    llm-d API Gateway - Routes requests to ModelService based on 'model' and 'owned_by' fields
    
    This gateway supports routing by both model name and inference engine type (owned_by).
    It can read 'owned_by' from request body or HTTP header (x-owned-by).
    """
    from fastapi import FastAPI, Request, HTTPException
    from fastapi.responses import StreamingResponse, JSONResponse
    from fastapi.middleware.cors import CORSMiddleware
    from pydantic import BaseModel
    import httpx
    import json
    import logging
    import os
    from typing import Dict, Any, Optional, Tuple, List
    from kubernetes import client, config
    from kubernetes.client.rest import ApiException

    # Configure logging
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)

    app = FastAPI(title="llm-d API Gateway")

    # CORS middleware
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

    # Service port (all ModelServices use 8000)
    SERVICE_PORT = 8000
    NAMESPACE = os.getenv("NAMESPACE", "llm-d-multi-model")

    # Initialize Kubernetes client
    try:
        config.load_incluster_config()
        logger.info("Loaded in-cluster Kubernetes config")
    except:
        try:
            config.load_kube_config()
            logger.info("Loaded kubeconfig from default location")
        except Exception as e:
            logger.warning(f"Could not load Kubernetes config: {e}. Service discovery will be limited.")

    v1 = client.CoreV1Api()

    # Routing configuration (can be updated dynamically)
    # Format: {(model_name, owned_by): service_name}
    # owned_by can be "vllm", "sglang", etc., or None for default
    # This will be auto-populated from Kubernetes Services, but can be manually configured
    ROUTING_CONFIG: Dict[Tuple[str, Optional[str]], str] = {
        # Example: Add your models here or let auto-discovery populate it
        # ("meta-llama/Llama-3.2-1B-Instruct", "vllm"): "ms-llama-32-1b-llm-d-modelservice-decode",
        # ("Qwen/Qwen2.5-0.5B-Instruct", "vllm"): "ms-qwen2-5-0-5b-llm-d-modelservice-decode",
    }

    def discover_services():
        """Discover ModelService instances from Kubernetes"""
        try:
            services = v1.list_namespaced_service(
                namespace=NAMESPACE,
                label_selector="llm-d.ai/role=decode"
            )
            
            discovered = {}
            for svc in services.items:
                # Extract model name from service name or labels
                # Service name format: ms-{model}-llm-d-modelservice-decode
                service_name = svc.metadata.name
                
                # Try to get model name from service labels
                labels = svc.metadata.labels or {}
                model_name = labels.get("llm-d.ai/model", "")
                
                # If no label, try to extract from service name
                if not model_name and "ms-" in service_name:
                    # Extract model identifier from service name
                    # ms-llama-32-1b-llm-d-modelservice-decode -> llama-32-1b
                    parts = service_name.replace("ms-", "").replace("-llm-d-modelservice-decode", "")
                    # Convert to model path format (approximate)
                    model_name = parts.replace("-", "/")
                
                # Default to vllm if no owned_by specified
                owned_by = labels.get("llm-d.ai/owned-by", "vllm")
                if not owned_by or owned_by == "":
                    owned_by = "vllm"
                
                if model_name:
                    key = (model_name, owned_by)
                    discovered[key] = service_name
                    logger.info(f"Discovered service: {model_name} (owned_by: {owned_by}) -> {service_name}")
            
            # Update routing config with discovered services
            ROUTING_CONFIG.update(discovered)
            return discovered
        except Exception as e:
            logger.warning(f"Failed to discover services from Kubernetes: {e}")
            return {}

    # Discover services on startup
    discover_services()

    # Pydantic models
    class RoutingMapping(BaseModel):
        model: str
        owned_by: Optional[str] = None
        service_name: str

    class RoutingMappingResponse(BaseModel):
        model: str
        owned_by: Optional[str]
        service_name: str

    def get_service_for_model_and_owned_by(model: str, owned_by: Optional[str] = None) -> Optional[str]:
        """
        Get corresponding Service name based on model name and owned_by
        
        Args:
            model: Model name from request
            owned_by: Inference engine type (vllm, sglang, etc.) from 'owned_by' field or header
        
        Returns:
            Service name or None if not found
        """
        # Normalize owned_by
        if owned_by:
            owned_by = owned_by.lower()
        
        # Try exact match with owned_by
        if owned_by:
            key = (model, owned_by)
            if key in ROUTING_CONFIG:
                service = ROUTING_CONFIG[key]
                if service:
                    logger.info(f"Matched model '{model}' with owned_by '{owned_by}' to service '{service}'")
                    return service
        
        # Try match with None (default/any owned_by)
        key = (model, None)
        if key in ROUTING_CONFIG:
            service = ROUTING_CONFIG[key]
            if service:
                logger.info(f"Matched model '{model}' (default owned_by) to service '{service}'")
                return service
        
        # Try default vllm
        key = (model, "vllm")
        if key in ROUTING_CONFIG:
            service = ROUTING_CONFIG[key]
            if service:
                logger.info(f"Matched model '{model}' (default vllm) to service '{service}'")
                return service
        
        # Fuzzy match - try to find similar model names
        model_lower = model.lower()
        for (key_model, key_owned_by), service in ROUTING_CONFIG.items():
            if service is None:
                continue
            
            # Check if model matches (fuzzy)
            key_model_lower = key_model.lower() if key_model else ""
            if key_model_lower in model_lower or model_lower in key_model_lower:
                # If owned_by matches or key_owned_by is None (default)
                if (key_owned_by is None) or (owned_by and key_owned_by == owned_by.lower()):
                    logger.info(f"Matched model '{model}' (fuzzy) with owned_by '{owned_by}' to service '{service}'")
                    return service
        
        # Return None if not found
        return None

    async def forward_request(
        service_name: str,
        path: str,
        method: str,
        headers: Dict[str, str],
        body: bytes = None,
        params: Dict[str, Any] = None
    ) -> httpx.Response:
        """Forward request to corresponding Service"""
        # Build target URL
        target_url = f"http://{service_name}.{NAMESPACE}.svc.cluster.local:{SERVICE_PORT}{path}"
        
        # Remove headers that shouldn't be forwarded
        forward_headers = {k: v for k, v in headers.items() 
                          if k.lower() not in ['host', 'content-length']}
        
        logger.info(f"Forwarding {method} {path} to {target_url}")
        
        async with httpx.AsyncClient(timeout=300.0) as client:
            if method == "GET":
                response = await client.get(target_url, headers=forward_headers, params=params)
            elif method == "POST":
                response = await client.post(
                    target_url,
                    headers=forward_headers,
                    content=body,
                    params=params
                )
            elif method == "DELETE":
                response = await client.delete(target_url, headers=forward_headers)
            else:
                raise HTTPException(status_code=405, detail=f"Method {method} not supported")
            
            return response

    @app.get("/health")
    async def health():
        """Health check"""
        return {"status": "healthy", "service": "llmd-api-gateway", "namespace": NAMESPACE}

    @app.post("/admin/discover")
    async def rediscover_services():
        """Manually trigger service discovery"""
        discovered = discover_services()
        return {"message": "Service discovery completed", "discovered": len(discovered), "services": discovered}

    @app.get("/admin/api/routing", response_model=List[RoutingMappingResponse])
    async def get_routing_config():
        """Get all routing mappings"""
        mappings = []
        for (model, owned_by), service_name in ROUTING_CONFIG.items():
            mappings.append(RoutingMappingResponse(
                model=model,
                owned_by=owned_by,
                service_name=service_name
            ))
        return mappings

    @app.post("/admin/api/routing", response_model=RoutingMappingResponse)
    async def add_routing_mapping(mapping: RoutingMapping):
        """Add a new routing mapping"""
        key = (mapping.model, mapping.owned_by)
        if key in ROUTING_CONFIG:
            raise HTTPException(
                status_code=400, 
                detail=f"Mapping already exists for model '{mapping.model}' with owned_by '{mapping.owned_by}'"
            )
        
        ROUTING_CONFIG[key] = mapping.service_name
        logger.info(f"Added routing mapping: {key} -> {mapping.service_name}")
        
        return RoutingMappingResponse(
            model=mapping.model,
            owned_by=mapping.owned_by,
            service_name=mapping.service_name
        )

    @app.delete("/admin/api/routing")
    async def delete_routing_mapping(model: str, owned_by: Optional[str] = None):
        """Delete a routing mapping"""
        if owned_by == "":
            owned_by = None
        
        key = (model, owned_by)
        if key not in ROUTING_CONFIG:
            raise HTTPException(
                status_code=404, 
                detail=f"Mapping not found for model '{model}' with owned_by '{owned_by}'"
            )
        
        del ROUTING_CONFIG[key]
        logger.info(f"Deleted routing mapping: {key}")
        
        return {"message": "Mapping deleted successfully"}

    @app.get("/v1/models")
    async def list_models():
        """List all available models from all ModelServices"""
        models = []
        seen_keys = set()
        
        # Get unique services
        unique_services = {service for service in ROUTING_CONFIG.values() if service is not None}
        
        for service_name in unique_services:
            try:
                async with httpx.AsyncClient(timeout=5.0) as client:
                    target_url = f"http://{service_name}.{NAMESPACE}.svc.cluster.local:{SERVICE_PORT}/v1/models"
                    response = await client.get(target_url)
                    if response.status_code == 200:
                        data = response.json()
                        if "data" in data:
                            for model in data["data"]:
                                model_id = model.get("id", "")
                                if model_id:
                                    # Find matching routing config
                                    for (model_name, owned_by), svc_name in ROUTING_CONFIG.items():
                                        if svc_name == service_name:
                                            # Check if model matches
                                            if model_id == model_name or model_name in model_id or model_id in model_name:
                                                key = (model_id, owned_by)
                                                if key not in seen_keys:
                                                    seen_keys.add(key)
                                                    engine_name = owned_by or "vllm"
                                                    
                                                    model_entry = model.copy()
                                                    model_entry["id"] = model_id
                                                    model_entry.pop("permission", None)
                                                    model_entry.pop("engine", None)
                                                    model_entry["owned_by"] = engine_name
                                                    models.append(model_entry)
            except Exception as e:
                logger.warning(f"Failed to get models from {service_name}: {e}")
        
        # Fallback: add from routing config if no models from services
        if not models:
            for (model_name, owned_by), service_name in ROUTING_CONFIG.items():
                if model_name and service_name is not None:
                    key = (model_name, owned_by)
                    if key not in seen_keys:
                        seen_keys.add(key)
                        engine_name = owned_by or "vllm"
                        models.append({
                            "id": model_name,
                            "object": "model",
                            "created": 0,
                            "owned_by": engine_name
                        })
        
        return {"object": "list", "data": models}

    @app.api_route("/v1/{path:path}", methods=["GET", "POST", "DELETE"])
    async def proxy_v1(request: Request, path: str):
        """Proxy all /v1/* requests"""
        # Read request body
        body = await request.body()
        
        # Parse request body to get model and owned_by fields
        model = None
        owned_by = None
        
        if body:
            try:
                body_json = json.loads(body)
                model = body_json.get("model")
                # Check for owned_by, engine, or inference_server field
                owned_by = (body_json.get("owned_by") or 
                           body_json.get("engine") or 
                           body_json.get("inference_server"))
            except json.JSONDecodeError:
                pass
        
        # If no model from body, try query parameters
        if not model:
            model = request.query_params.get("model")
        
        # If no owned_by from body, try header or query parameters
        if not owned_by:
            owned_by = (request.headers.get("x-owned-by") or
                       request.headers.get("X-Owned-By") or
                       request.query_params.get("owned_by") or
                       request.query_params.get("engine") or
                       request.query_params.get("inference_server"))
        
        # If still no model, return error
        if not model:
            raise HTTPException(
                status_code=400,
                detail="Missing 'model' field in request body, query parameters, or headers"
            )
        
        # Get corresponding Service based on model and owned_by
        service_name = get_service_for_model_and_owned_by(model, owned_by)
        if not service_name:
            # Try to discover services again
            discover_services()
            service_name = get_service_for_model_and_owned_by(model, owned_by)
            
            if not service_name:
                available_models = [f"{m} (owned_by: {o})" if o else m 
                                   for (m, o) in ROUTING_CONFIG.keys() if m]
                raise HTTPException(
                    status_code=404,
                    detail=f"Model '{model}' with owned_by '{owned_by}' not found. "
                           f"Available: {available_models}. "
                           f"Try calling POST /admin/discover to refresh service discovery."
                )
        
        logger.info(f"Routing request for model '{model}' with owned_by '{owned_by}' to service '{service_name}'")
        
        # Forward request
        try:
            response = await forward_request(
                service_name=service_name,
                path=f"/v1/{path}",
                method=request.method,
                headers=dict(request.headers),
                body=body,
                params=dict(request.query_params)
            )
            
            # Handle streaming response
            if "text/event-stream" in response.headers.get("content-type", ""):
                async def generate():
                    async for chunk in response.aiter_bytes():
                        yield chunk
                return StreamingResponse(generate(), media_type="text/event-stream")
            
            # Return JSON response
            return JSONResponse(
                content=response.json() if response.content else {},
                status_code=response.status_code,
                headers=dict(response.headers)
            )
        except httpx.TimeoutException:
            raise HTTPException(status_code=504, detail="Gateway timeout")
        except httpx.ConnectError:
            raise HTTPException(
                status_code=503,
                detail=f"Service '{service_name}' is not available. Please check if the pod is running."
            )
        except Exception as e:
            logger.error(f"Error forwarding request: {e}")
            raise HTTPException(status_code=500, detail=str(e))

    if __name__ == "__main__":
        import uvicorn
        uvicorn.run(app, host="0.0.0.0", port=8000)
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: llmd-api-gateway
  namespace: llm-d-multi-model
  labels:
    app: llmd-gateway
spec:
  replicas: 1
  selector:
    matchLabels:
      app: llmd-gateway
  template:
    metadata:
      labels:
        app: llmd-gateway
    spec:
      # Deploy to agent nodes, avoid control-plane
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: node-role.kubernetes.io/control-plane
                operator: DoesNotExist
      tolerations:
        - operator: "Exists"
      serviceAccountName: llmd-api-gateway
      containers:
      - name: gateway
        image: python:3.11-slim
        command:
        - /bin/bash
        - -c
        - |
          pip install fastapi uvicorn httpx kubernetes -q
          python /app/api-gateway.py
        ports:
        - containerPort: 8000
          name: http
        env:
        - name: NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        volumeMounts:
        - name: gateway-code
          mountPath: /app
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
      volumes:
      - name: gateway-code
        configMap:
          name: llmd-api-gateway-code
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: llmd-api-gateway
  namespace: llm-d-multi-model
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: llmd-api-gateway
  namespace: llm-d-multi-model
rules:
- apiGroups: [""]
  resources: ["services"]
  verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: llmd-api-gateway
  namespace: llm-d-multi-model
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: llmd-api-gateway
subjects:
- kind: ServiceAccount
  name: llmd-api-gateway
  namespace: llm-d-multi-model
---
apiVersion: v1
kind: Service
metadata:
  name: llmd-api-gateway
  namespace: llm-d-multi-model
  labels:
    app: llmd-gateway
spec:
  type: ClusterIP
  selector:
    app: llmd-gateway
  ports:
  - port: 8000
    targetPort: 8000
    protocol: TCP
    name: http
