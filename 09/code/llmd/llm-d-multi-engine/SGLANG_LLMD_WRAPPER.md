# SGLang ä½¿ç”¨ llm-d åŒ…è£…é•œåƒçš„å‘ç°

## å‘ç°

åœ¨ `/home/fuhwu/workspace/llm-d/guides/inference-scheduling/ms-inference-scheduling/values.yaml` ä¸­æ‰¾åˆ°äº†ä½¿ç”¨ `sglangServe` çš„ç¤ºä¾‹ï¼š

```yaml
containers:
- name: "sglang"
  image: ghcr.io/llm-d/llm-d-cuda:v0.4.0  # Use llm-d wrapper image (same as vLLM)
  modelCommand: sglangServe  # Use llm-d's sglangServe command
  args:
    - "--disable-uvicorn-access-log"
    - "--mem-fraction-static"
    - "0.2"
    - "--model-path"
    - Qwen/Qwen2.5-0.5B-Instruct
    - "--port"
    - "8200"
```

## å½“å‰çŠ¶æ€

### å°è¯•ä½¿ç”¨ sglangServe çš„ç»“æœ

å½“å°è¯•ä½¿ç”¨ `sglangServe` éƒ¨ç½²æ—¶ï¼Œé‡åˆ°äº†ä»¥ä¸‹é”™è¯¯ï¼š

```
Error: execution error at (llm-d-modelservice/templates/decode-deployment.yaml:43:13): 
.container.modelCommand is not as expected. 
Valid values are `vllmServe`, `imageDefault` and `custom`.
```

### åˆ†æ

1. **llm-d ç¤ºä¾‹æ–‡ä»¶**å±•ç¤ºäº† `sglangServe` çš„ç”¨æ³•
2. **å½“å‰éƒ¨ç½²çš„ Helm chart ç‰ˆæœ¬ (v0.3.8)** ä¸æ”¯æŒ `sglangServe`
3. **Chart æ¨¡æ¿éªŒè¯**åªå…è®¸ï¼š`vllmServe`, `imageDefault`, `custom`

## å¯èƒ½çš„åŸå› 

æ ¹æ® GitHub issue #403 ([llm-d/llm-d#403](https://github.com/llm-d/llm-d/issues/403))ï¼š

1. **åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­**ï¼šè¿™æ˜¯ä¸€ä¸ª EPIC issueï¼Œåˆ›å»ºäº 2025å¹´10æœˆ29æ—¥ï¼Œä¸“é—¨ç”¨äºè·Ÿè¸ª SGLang æ”¯æŒçš„å·¥ä½œ
2. **å¤šä»“åº“åä½œ**ï¼šéœ€è¦åœ¨å¤šä¸ª llm-d repos ä¸­è¿›è¡Œæ›´æ”¹ï¼š
   - llm-d/llm-d (ä¸»ä»“åº“)
   - llm-d-inference-scheduler (æ¨ç†è°ƒåº¦å™¨)
   - gateway-api-inference-extension (éœ€è¦åŸºæœ¬æ”¯æŒ)
3. **æ­£åœ¨è¿›è¡Œçš„å·¥ä½œ**ï¼š
   - PR #527 "Add SGLang option for inference-scheduling well-lit path" (2025å¹´12æœˆ3æ—¥)
   - å¤šä¸ªå­ä»»åŠ¡æ­£åœ¨å¼€å‘ä¸­ï¼ˆ#519, #520, #521ï¼‰
4. **ç¤ºä¾‹æ–‡ä»¶æ˜¯å‰ç»æ€§çš„**ï¼šç¤ºä¾‹æ–‡ä»¶å±•ç¤ºäº†æœªæ¥åŠŸèƒ½çš„ä½¿ç”¨æ–¹å¼ï¼Œä½†å½“å‰ chart ç‰ˆæœ¬å°šæœªå®ç°

## å½“å‰è§£å†³æ–¹æ¡ˆ

ç”±äº chart ä¸æ”¯æŒ `sglangServe`ï¼Œå½“å‰å¿…é¡»ä½¿ç”¨ï¼š

```yaml
containers:
- name: "sglang"
  image: lmsysorg/sglang:v0.5.6.post2-runtime  # ä½¿ç”¨å®˜æ–¹é•œåƒ
  modelCommand: custom  # ä½¿ç”¨ custom æ¨¡å¼
  command:
    - python3
    - -m
    - sglang.launch_server
  args:
    - --model-path
    - Qwen/Qwen2.5-0.5B-Instruct
    - --port
    - "8200"
    - --mem-fraction-static
    - "0.2"
```

## æœªæ¥æ–¹å‘

å¦‚æœæœªæ¥ chart æ”¯æŒ `sglangServe`ï¼Œå¯ä»¥è¿™æ ·é…ç½®ï¼š

```yaml
containers:
- name: "sglang"
  image: ghcr.io/llm-d/llm-d-cuda:v0.4.0
  modelCommand: sglangServe  # å¦‚æœæ”¯æŒçš„è¯
  args:
    - "--disable-uvicorn-access-log"
    - "--mem-fraction-static"
    - "0.2"
    - "--model-path"
    - Qwen/Qwen2.5-0.5B-Instruct
    - "--port"
    - "8200"
```

## ç›¸å…³èµ„æº

- **GitHub Issue**: [llm-d/llm-d#403 - [EPIC] Support sglang](https://github.com/llm-d/llm-d/issues/403)
- **ç›¸å…³ PR**: [PR #527 - Add SGLang option for inference-scheduling well-lit path](https://github.com/llm-d/llm-d/pull/527)
- **Inference Scheduler Issue**: [llm-d-inference-scheduler#394](https://github.com/llm-d/llm-d-inference-scheduler/issues/394)
- **Gateway API Extension**: [kubernetes-sigs/gateway-api-inference-extension#1141](https://github.com/kubernetes-sigs/gateway-api-inference-extension/issues/1141)

## æ€»ç»“

- âœ… llm-d ç¤ºä¾‹æ–‡ä»¶ä¸­å±•ç¤ºäº† `sglangServe` çš„ç”¨æ³•
- âŒ å½“å‰éƒ¨ç½²çš„ chart ç‰ˆæœ¬ (v0.3.8) ä¸æ”¯æŒ `sglangServe`
- âœ… SGLang ä»ç„¶é€šè¿‡ routing-proxy sidecar è·å¾— llm-d çš„éƒ¨åˆ†åŠŸèƒ½
- ğŸ”„ **SGLang æ”¯æŒæ˜¯ä¸€ä¸ªæ­£åœ¨è¿›è¡Œçš„ EPIC å·¥ä½œ**ï¼ˆGitHub issue #403ï¼Œåˆ›å»ºäº 2025å¹´10æœˆ29æ—¥ï¼‰
- â³ éœ€è¦ç­‰å¾…ç›¸å…³ PR åˆå¹¶å’Œ chart æ›´æ–°
