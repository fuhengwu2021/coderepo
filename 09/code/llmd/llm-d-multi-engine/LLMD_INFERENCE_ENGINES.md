# llm-d æ”¯æŒçš„æ¨ç†å¼•æ“

## å½“å‰æ”¯æŒçš„æ¨ç†å¼•æ“

### 1. vLLM âœ…
- **çŠ¶æ€**: å®Œå…¨æ”¯æŒï¼ˆé»˜è®¤æ¨ç†å¼•æ“ï¼‰
- **é•œåƒ**: `ghcr.io/llm-d/llm-d-cuda:v0.4.0` æˆ– `vllm/vllm-openai:v0.12.0`
- **modelCommand**: `vllmServe`
- **è¯´æ˜**: llm-d çš„ä¸»è¦æ¨ç†å¼•æ“ï¼Œæ‰€æœ‰ well-lit paths éƒ½å›´ç»• vLLM è®¾è®¡

### 2. SGLang ğŸ”„
- **çŠ¶æ€**: æ­£åœ¨å¼€å‘ä¸­
- **GitHub Issue**: [llm-d/llm-d#403](https://github.com/llm-d/llm-d/issues/403)
- **é•œåƒ**: `lmsysorg/sglang:v0.5.6.post2-runtime`ï¼ˆå½“å‰ä½¿ç”¨å®˜æ–¹é•œåƒï¼‰
- **modelCommand**: `sglangServe`ï¼ˆè®¡åˆ’ä¸­ï¼Œä½†å½“å‰ chart ä¸æ”¯æŒï¼‰
- **å½“å‰æ–¹æ¡ˆ**: ä½¿ç”¨ `custom` æ¨¡å¼ + å®˜æ–¹é•œåƒ
- **è¿›å±•**: PR #527 æ­£åœ¨æ·»åŠ  SGLang æ”¯æŒ

## ä¸æ”¯æŒçš„æ¨ç†å¼•æ“

### TensorRT / TensorRT-LLM âŒ
- **çŠ¶æ€**: æœªæ‰¾åˆ°æ”¯æŒ
- **æœç´¢èŒƒå›´**: 
  - llm-d ä¸»ä»“åº“
  - æ–‡æ¡£å’Œææ¡ˆ
  - GitHub issues
- **ç»“æœ**: æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å…³äº TensorRT æˆ– TensorRT-LLM çš„å¼•ç”¨æˆ–æ”¯æŒ

## llm-d çš„è®¾è®¡åŸåˆ™

æ ¹æ® `docs/proposals/modelservice.md`ï¼š

> **Prioritize non-vLLM serving engines (initially):** llm-d follows a **vLLM-first but not vLLM-only** design principle. ModelService follows the same.

è¿™æ„å‘³ç€ï¼š
- llm-d é‡‡ç”¨ "vLLM-first but not vLLM-only" çš„è®¾è®¡åŸåˆ™
- æœªæ¥å¯èƒ½ä¼šæ”¯æŒå…¶ä»–æ¨ç†å¼•æ“
- ä½†ç›®å‰ä¸»è¦å›´ç»• vLLM æ„å»º

## æ¶æ„è¯´æ˜

æ ¹æ® `README.md`ï¼š

> llm-d accelerates distributed inference by integrating industry-standard open technologies: **vLLM as default model server and engine**, Inference Gateway as request scheduler and balancer, and Kubernetes as infrastructure orchestrator and workload control plane.

llm-d çš„æ ¸å¿ƒæ¶æ„ï¼š
- **é»˜è®¤æ¨¡å‹æœåŠ¡å™¨**: vLLM
- **è¯·æ±‚è°ƒåº¦å™¨**: Inference Gateway
- **åŸºç¡€è®¾æ–½ç¼–æ’**: Kubernetes

## å¦‚ä½•æ·»åŠ æ–°çš„æ¨ç†å¼•æ“æ”¯æŒ

å¦‚æœéœ€è¦æ·»åŠ  TensorRT-LLM æˆ–å…¶ä»–æ¨ç†å¼•æ“æ”¯æŒï¼Œå¯ä»¥å‚è€ƒï¼š

1. **GitHub Issue #403** - SGLang æ”¯æŒçš„å®ç°æ–¹å¼
2. **ModelService Helm Chart** - éœ€è¦æ·»åŠ æ–°çš„ `modelCommand` ç±»å‹
3. **Inference Gateway Extension** - å¯èƒ½éœ€è¦æ·»åŠ ç›¸åº”çš„æ”¯æŒ

## æ€»ç»“

| æ¨ç†å¼•æ“ | çŠ¶æ€ | è¯´æ˜ |
|---------|------|------|
| vLLM | âœ… å®Œå…¨æ”¯æŒ | é»˜è®¤æ¨ç†å¼•æ“ï¼Œæ‰€æœ‰åŠŸèƒ½éƒ½å›´ç»• vLLM |
| SGLang | ğŸ”„ å¼€å‘ä¸­ | issue #403ï¼ŒPR #527 è¿›è¡Œä¸­ |
| TensorRT | âŒ ä¸æ”¯æŒ | æœªæ‰¾åˆ°ç›¸å…³æ”¯æŒ |
| TensorRT-LLM | âŒ ä¸æ”¯æŒ | æœªæ‰¾åˆ°ç›¸å…³æ”¯æŒ |

## ç›¸å…³èµ„æº

- [llm-d README](https://github.com/llm-d/llm-d)
- [ModelService Proposal](https://github.com/llm-d/llm-d/blob/main/docs/proposals/modelservice.md)
- [SGLang Support Issue #403](https://github.com/llm-d/llm-d/issues/403)
- [TensorRT-LLM GitHub](https://github.com/NVIDIA/TensorRT-LLM)
