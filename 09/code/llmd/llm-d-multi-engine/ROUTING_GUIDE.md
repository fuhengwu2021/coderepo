# è·¯ç”±å’Œå¯¹æ¯”æµ‹è¯•æŒ‡å—

## 1. èµ„æºç«äº‰å’Œ Race Condition åˆ†æ

### âœ… å½“å‰é…ç½®çš„èµ„æºéš”ç¦»æƒ…å†µ

**GPU éš”ç¦»ï¼ˆå®Œå…¨éš”ç¦»ï¼‰**ï¼š
- vLLM: `NVIDIA_VISIBLE_DEVICES=0` â†’ ä½¿ç”¨ GPU 0
- SGLang: `NVIDIA_VISIBLE_DEVICES=1` â†’ ä½¿ç”¨ GPU 1
- âœ… **æ—  GPU ç«äº‰**ï¼šæ¯ä¸ªæœåŠ¡ä½¿ç”¨ç‹¬ç«‹çš„ GPU

**å†…å­˜éš”ç¦»ï¼ˆéƒ¨åˆ†éš”ç¦»ï¼‰**ï¼š
- vLLM: `--gpu-memory-utilization=0.1` â†’ ä½¿ç”¨ GPU 0 çš„ 10% å†…å­˜
- SGLang: `--mem-fraction-static=0.1` â†’ ä½¿ç”¨ GPU 1 çš„ 10% å†…å­˜
- âœ… **GPU å†…å­˜å®Œå…¨éš”ç¦»**ï¼šä¸åŒ GPUï¼Œæ— ç«äº‰
- âš ï¸ **ç³»ç»Ÿå†…å­˜å…±äº«**ï¼šä¸¤ä¸ª pod å…±äº«èŠ‚ç‚¹çš„ç³»ç»Ÿå†…å­˜ï¼ˆä½†æ¯ä¸ª pod æœ‰ limits: 8Giï¼‰

**CPU èµ„æºï¼ˆå…±äº«ä½†æœ‰ limitsï¼‰**ï¼š
- âš ï¸ **CPU å…±äº«**ï¼šä¸¤ä¸ª pod å…±äº«èŠ‚ç‚¹çš„ CPU
- âœ… **æœ‰èµ„æºé™åˆ¶**ï¼šæ¯ä¸ª pod æœ‰ CPU requests/limitsï¼ˆå¦‚æœè®¾ç½®äº†ï¼‰
- ğŸ’¡ **å»ºè®®**ï¼šå¦‚æœå‘ç° CPU ç«äº‰ï¼Œå¯ä»¥è®¾ç½® CPU limits

**ç£ç›˜ I/Oï¼ˆå…±äº«ï¼‰**ï¼š
- âš ï¸ **æ¨¡å‹å­˜å‚¨å…±äº«**ï¼šä¸¤ä¸ª pod éƒ½è®¿é—® `/models` ç›®å½•
- âœ… **åªè¯»è®¿é—®**ï¼šæ¨¡å‹æ–‡ä»¶æ˜¯åªè¯»çš„ï¼Œä¸ä¼šæœ‰å†™å†²çª
- âš ï¸ **ç¼“å­˜å†™å…¥**ï¼šHuggingFace ç¼“å­˜å†™å…¥åˆ° `/models/hub`ï¼Œå¯èƒ½æœ‰è½»å¾®ç«äº‰

**ç½‘ç»œå¸¦å®½ï¼ˆå…±äº«ï¼‰**ï¼š
- âš ï¸ **å…±äº«ç½‘ç»œ**ï¼šä¸¤ä¸ªæœåŠ¡å…±äº«èŠ‚ç‚¹çš„ç½‘ç»œå¸¦å®½
- ğŸ’¡ **å½±å“è¾ƒå°**ï¼šå¯¹äºæ¨ç†æœåŠ¡ï¼Œç½‘ç»œå¸¦å®½é€šå¸¸ä¸æ˜¯ç“¶é¢ˆ

### Race Condition åˆ†æ

**âŒ ä¸ä¼šæœ‰ Race Condition**ï¼š
- ä¸¤ä¸ª pod æ˜¯**ç‹¬ç«‹çš„è¿›ç¨‹**ï¼Œä¸å…±äº«å†…å­˜ç©ºé—´
- æ¯ä¸ªæœåŠ¡è¿è¡Œåœ¨è‡ªå·±çš„å®¹å™¨ä¸­ï¼Œæœ‰ç‹¬ç«‹çš„è¿›ç¨‹ç©ºé—´
- æ¨¡å‹æ–‡ä»¶æ˜¯**åªè¯»çš„**ï¼Œä¸ä¼šæœ‰å†™å†²çª
- GPU å†…å­˜å®Œå…¨éš”ç¦»ï¼Œä¸ä¼šæœ‰å†…å­˜ç«äº‰

**å¯èƒ½çš„èµ„æºç«äº‰ç‚¹**ï¼š
1. **CPU ç«äº‰**ï¼šå¦‚æœä¸¤ä¸ªæœåŠ¡åŒæ—¶é«˜è´Ÿè½½ï¼Œå¯èƒ½ç«äº‰ CPU
2. **ç³»ç»Ÿå†…å­˜ç«äº‰**ï¼šå¦‚æœä¸¤ä¸ªæœåŠ¡åŒæ—¶åŠ è½½å¤§é‡æ•°æ®åˆ°ç³»ç»Ÿå†…å­˜
3. **ç£ç›˜ I/O ç«äº‰**ï¼šå¦‚æœåŒæ—¶è¯»å–æ¨¡å‹æ–‡ä»¶ï¼ˆä½†æ¨¡å‹é€šå¸¸å·²åŠ è½½åˆ° GPU å†…å­˜ï¼‰

### å¯¹æ¯”æµ‹è¯•çš„å…¬å¹³æ€§

**âœ… å½“å‰é…ç½®é€‚åˆå¯¹æ¯”æµ‹è¯•**ï¼š
- ç›¸åŒçš„ç¡¬ä»¶ç¯å¢ƒï¼ˆåŒä¸€èŠ‚ç‚¹ï¼‰
- GPU å®Œå…¨éš”ç¦»ï¼ˆä¸åŒ GPUï¼‰
- ç›¸åŒçš„æ¨¡å‹ï¼ˆQwen2.5-0.5B-Instructï¼‰
- ç›¸åŒçš„ GPU å†…å­˜ä½¿ç”¨ç‡ï¼ˆéƒ½æ˜¯ 10%ï¼‰

**âš ï¸ éœ€è¦æ³¨æ„çš„å˜é‡**ï¼š
- CPU ç«äº‰å¯èƒ½å½±å“ç»“æœï¼ˆä½†å¯ä»¥é€šè¿‡ CPU limits æ§åˆ¶ï¼‰
- ç³»ç»Ÿå†…å­˜ç«äº‰ï¼ˆé€šå¸¸å½±å“è¾ƒå°ï¼‰
- ç½‘ç»œå»¶è¿Ÿï¼ˆåŒä¸€èŠ‚ç‚¹ï¼Œå½±å“å¾ˆå°ï¼‰

## 2. è·¯ç”±æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1: ç›´æ¥é€šè¿‡ Service è®¿é—®ï¼ˆæœ€ç®€å•ï¼‰

æ¯ä¸ª LLMInferenceService ä¼šè‡ªåŠ¨åˆ›å»º Kubernetes Serviceï¼š

```bash
# è®¿é—® vLLM
kubectl port-forward svc/vllm-qwen2-5-0-5b 8001:8000
curl http://localhost:8001/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "Qwen/Qwen2.5-0.5B-Instruct",
    "messages": [{"role": "user", "content": "Hello"}]
  }'

# è®¿é—® SGLang
kubectl port-forward svc/sglang-qwen2-5-0-5b 8002:8000
curl http://localhost:8002/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "Qwen/Qwen2.5-0.5B-Instruct",
    "messages": [{"role": "user", "content": "Hello"}]
  }'
```

### æ–¹æ¡ˆ 2: é€šè¿‡ API Gateway è·¯ç”±ï¼ˆæ¨èç”¨äºå¯¹æ¯”æµ‹è¯•ï¼‰

åˆ›å»ºä¸€ä¸ª API Gatewayï¼Œæ ¹æ®è¯·æ±‚ä¸­çš„ `inference_server` å­—æ®µè·¯ç”±åˆ°ä¸åŒçš„æœåŠ¡ã€‚

**ä¼˜ç‚¹**ï¼š
- ç»Ÿä¸€çš„å…¥å£ç‚¹
- å¯ä»¥é€šè¿‡è¯·æ±‚å‚æ•°é€‰æ‹©å¼•æ“
- æ–¹ä¾¿è¿›è¡Œ A/B æµ‹è¯•

**å®ç°æ–¹å¼**ï¼šè§ä¸‹é¢çš„ `api-gateway.yaml`

### æ–¹æ¡ˆ 3: é€šè¿‡ llm-d InferencePoolï¼ˆå¦‚æœä½¿ç”¨ llm-d å®Œæ•´åŠŸèƒ½ï¼‰

å¦‚æœéƒ¨ç½²äº† llm-d çš„ InferencePoolï¼Œå¯ä»¥é€šè¿‡ `owned_by` æ ‡ç­¾è¿›è¡Œè·¯ç”±ã€‚

## 3. å¯¹æ¯”æµ‹è¯•è„šæœ¬ç¤ºä¾‹

```bash
#!/bin/bash
# benchmark-comparison.sh

# æµ‹è¯•å‚æ•°
MODEL="Qwen/Qwen2.5-0.5B-Instruct"
NUM_REQUESTS=100
CONCURRENT=10

# æµ‹è¯• vLLM
echo "Testing vLLM..."
kubectl port-forward svc/vllm-qwen2-5-0-5b 8001:8000 &
VLLM_PF=$!
sleep 2

time for i in $(seq 1 $NUM_REQUESTS); do
  curl -s http://localhost:8001/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d "{\"model\": \"$MODEL\", \"messages\": [{\"role\": \"user\", \"content\": \"Test $i\"}]}" \
    > /dev/null &
  if [ $((i % $CONCURRENT)) -eq 0 ]; then
    wait
  fi
done
wait

kill $VLLM_PF

# æµ‹è¯• SGLang
echo "Testing SGLang..."
kubectl port-forward svc/sglang-qwen2-5-0-5b 8002:8000 &
SGLANG_PF=$!
sleep 2

time for i in $(seq 1 $NUM_REQUESTS); do
  curl -s http://localhost:8002/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d "{\"model\": \"$MODEL\", \"messages\": [{\"role\": \"user\", \"content\": \"Test $i\"}]}" \
    > /dev/null &
  if [ $((i % $CONCURRENT)) -eq 0 ]; then
    wait
  fi
done
wait

kill $SGLANG_PF
```

## 4. ä¼˜åŒ–å»ºè®®

### å¦‚æœå‘ç° CPU ç«äº‰

åœ¨ LLMInferenceService ä¸­æ·»åŠ  CPU limitsï¼š

```yaml
resources:
  requests:
    nvidia.com/gpu: 1
    memory: 6Gi
    cpu: "2"  # æ·»åŠ  CPU request
  limits:
    nvidia.com/gpu: 1
    memory: 8Gi
    cpu: "4"  # æ·»åŠ  CPU limit
```

### å¦‚æœå‘ç°ç³»ç»Ÿå†…å­˜ç«äº‰

å¢åŠ å†…å­˜ limits æˆ–å‡å°‘å¹¶å‘è¯·æ±‚æ•°ã€‚

### ç›‘æ§èµ„æºä½¿ç”¨

```bash
# ç›‘æ§èŠ‚ç‚¹èµ„æº
kubectl top node

# ç›‘æ§ pod èµ„æº
kubectl top pod -l app=vllm
kubectl top pod -l app=sglang

# ç›‘æ§ GPU ä½¿ç”¨
nvidia-smi
```
